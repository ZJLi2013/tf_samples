{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ab2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only tf2 \n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52044628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kmonachopoulos/ImageNet-to-TFrecord\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Wrapper for inserting float features into Example proto.\"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b849eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_example(filename, image_buffer, label, synset, human,\n",
    "                        height, width):\n",
    "    \"\"\"Build an Example proto for an example.\n",
    "\n",
    "  Args:\n",
    "    filename: string, path to an image file, e.g., '/path/to/example.JPG'\n",
    "    image_buffer: string, JPEG encoding of RGB image\n",
    "    label: integer, identifier for the ground truth for the network\n",
    "    synset: string, unique WordNet ID specifying the label, e.g., 'n02323233'\n",
    "    human: string, human-readable label, e.g., 'red fox, Vulpes vulpes'\n",
    "    height: integer, image height in pixels\n",
    "    width: integer, image width in pixels\n",
    "  Returns:\n",
    "    Example proto\n",
    "    \"\"\"\n",
    "\n",
    "    colorspace = b'RGB'\n",
    "    channels = 3\n",
    "    image_format = b'JPEG'\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': _int64_feature(height),\n",
    "      'image/width': _int64_feature(width),\n",
    "      'image/colorspace': _bytes_feature(colorspace),\n",
    "      'image/channels': _int64_feature(channels),\n",
    "      'image/class/label': _int64_feature(label),\n",
    "      'image/class/synset': _bytes_feature(bytes(synset,'utf-8')),\n",
    "      'image/class/text': _bytes_feature(bytes(human,'utf-8')),\n",
    "      'image/format': _bytes_feature(image_format),\n",
    "      'image/filename': _bytes_feature(bytes(os.path.basename(filename),'utf-8')),\n",
    "      'image/encoded': _bytes_feature(image_buffer)}))\n",
    "  \n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddcff135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCoder(object):\n",
    "    \"\"\"helper class that provides TF iamge coding utils\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def decode_jpeg(self, image_data):\n",
    "        image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "        assert len(image.shape) == 3\n",
    "        assert image.shape[2] == 3\n",
    "        return image    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4e8e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image(filename, coder):\n",
    "    image_data = tf.io.gfile.GFile(filename, 'rb').read()\n",
    "    # in normal mode:  image_data = open(filename, 'rb').read()\n",
    "    image = coder.decode_jpeg(image_data)\n",
    "    # Check that image converted to RGB\n",
    "    assert len(image.shape) == 3\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    assert image.shape[2] == 3\n",
    "\n",
    "    return image_data, height, width    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bf58d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"/data/ImageNet_tiny/\"\n",
    "\n",
    "def _process_image_files_batch(coder, thread_index, ranges, name, filenames,\n",
    "                               synsets, labels, humans, num_shards):\n",
    "    \"\"\"Processes and saves list of images as TFRecord in 1 thread.\n",
    "\n",
    "  Args:\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "    thread_index: integer, unique batch to run index is within [0, len(ranges)).\n",
    "    ranges: list of pairs of integers specifying ranges of each batches to\n",
    "      analyze in parallel.\n",
    "    name: string, unique identifier specifying the data set\n",
    "    filenames: list of strings; each string is a path to an image file\n",
    "    synsets: list of strings; each string is a unique WordNet ID\n",
    "    labels: list of integer; each integer identifies the ground truth\n",
    "    humans: list of strings; each string is a human-readable label\n",
    "    num_shards: integer number of shards for this data set.\n",
    "    \"\"\"\n",
    "  # Each thread produces N shards where N = int(num_shards / num_threads).\n",
    "  # For instance, if num_shards = 128, and the num_threads = 2, then the first\n",
    "  # thread would produce shards [0, 64).\n",
    "    \n",
    "    global output_directory\n",
    "    \n",
    "    num_threads = len(ranges)\n",
    "    assert not num_shards % num_threads\n",
    "    num_shards_per_batch = int(num_shards / num_threads)\n",
    "    print(\"**************num_shards_per_batch********** \", num_shards_per_batch)  #1031\n",
    "    shard_ranges = np.linspace(ranges[thread_index][0],\n",
    "                             ranges[thread_index][1],\n",
    "                             num_shards_per_batch + 1).astype(int)\n",
    "    num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
    "    counter = 0\n",
    "    for s in  xrange(num_shards_per_batch):\n",
    "     # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n",
    "        shard = thread_index * num_shards_per_batch + s\n",
    "        output_filename = '%s-%.5d-of-%.5d' % (name, shard, num_shards)\n",
    "        output_file = os.path.join(output_directory, output_filename)\n",
    "        writer = tf.io.TFRecordWriter(output_file)   \n",
    "        \n",
    "        shard_counter = 0\n",
    "        files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int) # HERE\n",
    "        for i in files_in_shard:\n",
    "            filename = filenames[i]\n",
    "            label = labels[i]\n",
    "            synset = synsets[i]\n",
    "            human = humans[i]\n",
    "\n",
    "            image_buffer, height, width = _process_image(filename, coder)\n",
    "            example = _convert_to_example(filename, image_buffer, label, synset, human, height, width)\n",
    "            writer.write(example.SerializeToString())\n",
    "            shard_counter += 1\n",
    "            counter += 1\n",
    "            \n",
    "            if not counter % 1000:\n",
    "                print('%s [thread %d]: Processed %d of %d images in thread batch.' %\n",
    "                  (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "                sys.stdout.flush()\n",
    "        \n",
    "        writer.close()\n",
    "        print('%s [thread %d]: Wrote %d images to %s' %\n",
    "               (datetime.now(), thread_index, shard_counter, output_file))\n",
    "        sys.stdout.flush()\n",
    "        shard_counter = 0\n",
    "    print('%s [thread %d]: Wrote %d images to %d shards.' %\n",
    "           (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "    sys.stdout.flush()       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6637504",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 1\n",
    "\n",
    "def _process_image_files(name, filenames, synsets, labels, humans, num_shards):\n",
    "    \"\"\"Process and save list of images as TFRecord of Example protos.\n",
    "\n",
    "  Args:\n",
    "    name: string, unique identifier specifying the data set\n",
    "    filenames: list of strings; each string is a path to an image file\n",
    "    synsets: list of strings; each string is a unique WordNet ID\n",
    "    labels: list of integer; each integer identifies the ground truth\n",
    "    humans: list of strings; each string is a human-readable label\n",
    "    num_shards: integer number of shards for this data set.\n",
    "    \"\"\"\n",
    "    assert len(filenames) == len(synsets)\n",
    "    assert len(filenames) == len(labels)\n",
    "    assert len(filenames) == len(humans)\n",
    "    \n",
    "    global num_threads \n",
    "\n",
    "    # Break all images into batches with a [ranges[i][0], ranges[i][1]].\n",
    "    spacing = np.linspace(0, len(filenames), num_threads + 1).astype(np.int)\n",
    "    ranges = []\n",
    "    threads = []\n",
    "    for i in xrange(len(spacing) - 1):\n",
    "        ranges.append([spacing[i], spacing[i+1]])\n",
    "\n",
    "    # Launch a thread for each batch.\n",
    "    print('Launching %d threads for spacings: %s' % (num_threads, ranges))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    coder = ImageCoder()\n",
    "    threads = []\n",
    "    for thread_idx in xrange(len(ranges)):\n",
    "        args = (coder, thread_idx, ranges, name, filenames, synsets, labels, humans, num_shards)\n",
    "        t = threading.Thread(target=_process_image_files_batch, args=args)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    \n",
    "    coord.join(threads)\n",
    "    print('%s: Finished writing all %d images in data set.' %\n",
    "           (datetime.now(), len(filenames)))\n",
    "    sys.stdout.flush()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f998cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_image_files(data_dir, labels_file):\n",
    "    \"\"\"Build a list of all images files and labels in the data set.\n",
    "\n",
    "  Args:\n",
    "    data_dir: string, path to the root directory of images.\n",
    "\n",
    "      Assumes that the ImageNet data set resides in JPEG files located in\n",
    "      the following directory structure.\n",
    "\n",
    "        data_dir/n01440764/ILSVRC2012_val_00000293.JPEG\n",
    "        data_dir/n01440764/ILSVRC2012_val_00000543.JPEG\n",
    "\n",
    "      where 'n01440764' is the unique synset label associated with these images.\n",
    "\n",
    "    labels_file: string, path to the labels file.\n",
    "\n",
    "      The list of valid labels are held in this file. Assumes that the file\n",
    "      contains entries as such:\n",
    "        n01440764\n",
    "        n01443537\n",
    "        n01484850\n",
    "      where each line corresponds to a label expressed as a synset. We map\n",
    "      each synset contained in the file to an integer (based on the alphabetical\n",
    "      ordering) starting with the integer 1 corresponding to the synset\n",
    "      contained in the first line.\n",
    "\n",
    "      The reason we start the integer labels at 1 is to reserve label 0 as an\n",
    "      unused background class.\n",
    "\n",
    "  Returns:\n",
    "    filenames: list of strings; each string is a path to an image file.\n",
    "    synsets: list of strings; each string is a unique WordNet ID.\n",
    "    labels: list of integer; each integer identifies the ground truth.\n",
    "    \"\"\"\n",
    "    print('Determining list of input files and labels from %s.' % data_dir)\n",
    "    challenge_synsets = [l.strip() for l in\n",
    "                   tf.io.gfile.GFile(labels_file, 'r').readlines()]\n",
    "\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    synsets = []\n",
    "\n",
    "    # Leave label index 0 empty as a background class.\n",
    "    label_index = 1\n",
    "\n",
    "    # Construct the list of JPEG files and labels.\n",
    "    for synset in challenge_synsets:\n",
    "        jpeg_file_path = '%s/%s/*.JPEG' % (data_dir, synset)\n",
    "        matching_files = tf.io.gfile.glob(jpeg_file_path)\n",
    "\n",
    "        labels.extend([label_index] * len(matching_files))\n",
    "        synsets.extend([synset] * len(matching_files))\n",
    "        filenames.extend(matching_files)\n",
    "\n",
    "        if not label_index % 100:\n",
    "            print('Finished finding files in %d of %d classes.' % (\n",
    "                      label_index, len(challenge_synsets)))\n",
    "            label_index += 1\n",
    "\n",
    "    # Shuffle the ordering of all image files in order to guarantee\n",
    "    # random ordering of the images with respect to label in the\n",
    "    # saved TFRecord files. Make the randomization repeatable.\n",
    "    shuffled_index = range(len(filenames))\n",
    "    random.seed(12345)\n",
    "\n",
    "    random.shuffle(list(range(len(shuffled_index))))\n",
    "\n",
    "    filenames = [filenames[i] for i in shuffled_index]\n",
    "    synsets = [synsets[i] for i in shuffled_index]\n",
    "    labels = [labels[i] for i in shuffled_index]\n",
    "\n",
    "    print('Found %d JPEG files across %d labels inside %s.' %\n",
    "            (len(filenames), len(challenge_synsets), data_dir))\n",
    "    return filenames, synsets, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40478e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_human_readable_labels(synsets, synset_to_human):\n",
    "    humans = []\n",
    "    for s in synsets:\n",
    "        assert s in synset_to_human, ('Failed to find: %s' % s)\n",
    "        humans.append(synset_to_human[s])\n",
    "    return humans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9997bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_dataset(name, directory, num_shards, synset_to_human):\n",
    "    \"\"\" process a complete dataset and save it to TFRecord\"\"\"\n",
    "    filenames, syssets, labels = _find_image_files(directory, \"/data/ImageNet_tiny/imagenet_lsvrc_2015_synsets_tiny.txt\")\n",
    "    humans = _find_human_readable_labels(syssets, synset_to_human)\n",
    "    _process_image_files(name, filenames, syssets, labels, humans, num_shards)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bbd24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_sysset_lookup():\n",
    "    \"\"\" build lookup for synset to human-readable label\"\"\"\n",
    "    imagenet_metadata_file = \"/data/ImageNet_tiny/imagenet_metadata_tiny.txt\"\n",
    "    lines = tf.io.gfile.GFile(imagenet_metadata_file, 'r').readlines()\n",
    "    sysnet_to_human = {}\n",
    "    for l in lines:\n",
    "        if l :\n",
    "            parts = l.strip().split('\\t')\n",
    "            assert len(parts) == 2 \n",
    "            sysnet = parts[0]\n",
    "            human = parts[1]\n",
    "            sysnet_to_human[sysnet] = human\n",
    "    return sysnet_to_human\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e47e778c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining list of input files and labels from /home/lidavid/data/ImageNet_tiny/.\n",
      "Found 1300 JPEG files across 1 labels inside /home/lidavid/data/ImageNet_tiny/.\n",
      "Launching 1 threads for spacings: [[0, 1300]]\n",
      "**************num_shards_per_batch**********  1\n",
      "2021-06-09 14:43:40.195295 [thread 0]: Processed 1000 of 1300 images in thread batch.\n",
      "2021-06-09 14:43:40.676097 [thread 0]: Wrote 1300 images to /home/lidavid/data/ImageNet_tiny/train-00000-of-00001\n",
      "2021-06-09 14:43:40.676566 [thread 0]: Wrote 1300 images to 1300 shards.\n",
      "2021-06-09 14:43:40.729073: Finished writing all 1300 images in data set.\n"
     ]
    }
   ],
   "source": [
    "#test \n",
    "train_dir=\"/home/lidavid/data/ImageNet_tiny/\"\n",
    "train_shards = 1 # number of shards in training TFRecord files\n",
    "sysnet_to_human = _build_sysset_lookup()\n",
    "_process_dataset(\"train\", train_dir, train_shards, sysnet_to_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0e51a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check generated ImageNet tfrecords \n",
    "import os\n",
    "tiny_path = \"/data/ImageNet_tiny/\"\n",
    "record_name = \"train-00000-of-00001\"\n",
    "raw_dataset = tf.data.TFRecordDataset(os.path.join(tiny_path + record_name))\n",
    "\n",
    "c = 0 \n",
    "for sample in raw_dataset:\n",
    "    c += 1\n",
    "    \n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8add6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
